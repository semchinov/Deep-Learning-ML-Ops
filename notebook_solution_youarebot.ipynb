{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 98885,
     "databundleVersionId": 11800270,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# KAGGLE DOWNLOADING DELETED\n",
    "# LOCAL DOWNLOAD FROM LOCAL FILES IMPLEMENTED"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation"
   ],
   "metadata": {
    "id": "da4eb2d4-2b96-4de3-8b2b-f55b1ea9f9c7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pathlib"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:11.221927Z",
     "iopub.execute_input": "2025-07-06T13:39:11.222341Z",
     "iopub.status.idle": "2025-07-06T13:39:11.227769Z",
     "shell.execute_reply.started": "2025-07-06T13:39:11.222315Z",
     "shell.execute_reply": "2025-07-06T13:39:11.226456Z"
    },
    "id": "e03e0d76"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def set_all_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_all_seeds(42)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:11.229259Z",
     "iopub.execute_input": "2025-07-06T13:39:11.229687Z",
     "iopub.status.idle": "2025-07-06T13:39:11.255916Z",
     "shell.execute_reply.started": "2025-07-06T13:39:11.229647Z",
     "shell.execute_reply": "2025-07-06T13:39:11.254993Z"
    },
    "id": "d8209733"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Загрузка и обработка данных"
   ],
   "metadata": {
    "id": "f838dead-c7ab-4791-a2c6-6d4038fa2c61"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "base_path = pathlib.Path('data/you-are-bot')\n",
    "\n",
    "path_train = base_path / 'train.json'\n",
    "path_test = base_path / 'test.json'\n",
    "\n",
    "path_y_train = base_path / 'ytrain.csv'\n",
    "path_y_test = base_path / 'ytest.csv'\n",
    "\n",
    "path_sample_submission = base_path / 'sample_submission.csv'\n",
    "\n",
    "with open(path_train, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(path_test, 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "submission = pd.read_csv(path_sample_submission)\n",
    "y_train_data = pd.read_csv(path_y_train)\n",
    "y_test_data = pd.read_csv(path_y_test)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_data))\n",
    "print(\"Number of test samples:\", len(test_data))\n",
    "\n",
    "rename_map = {\"participant_index\" : 'person'}\n",
    "\n",
    "dataset_train = []\n",
    "\n",
    "for dialog_id, dialog in train_data.items():\n",
    "    mask = y_train_data['dialog_id'] == dialog_id\n",
    "    # Ensure that labels are sorted by participant_index\n",
    "    y = y_train_data[mask][['participant_index', 'is_bot']].sort_values(by='participant_index', ascending=1)['is_bot'].to_list()\n",
    "    # Creating labels\n",
    "    p0_bot = str(int(y[0]))\n",
    "    p1_bot = str(int(y[1]))\n",
    "    s = p0_bot + p1_bot\n",
    "    label_map = {\n",
    "        '01' : 0, # p0 human, p1 bot\n",
    "        '10' : 1, # p0 bot, p1 human\n",
    "        '00' : 2, # both human\n",
    "    }\n",
    "    label = label_map[s]\n",
    "    # Rename keys in dialog items\n",
    "    rename_set_keys = lambda s, names : {names.get(k, k): v for k, v in s.items()}\n",
    "    dialog = [rename_set_keys(item, rename_map) for item in dialog]\n",
    "    # Create data entry\n",
    "    data = {\n",
    "        'dialog': dialog,\n",
    "        'label': label,\n",
    "        'dialog_id': dialog_id,\n",
    "        'p0_bot': int(p0_bot),\n",
    "        'p1_bot': int(p1_bot),\n",
    "    }\n",
    "    dataset_train.append(data)\n",
    "\n",
    "dataset_test = []\n",
    "for dialog_id, dialog in test_data.items():\n",
    "    dialog = [rename_set_keys(item, rename_map) for item in dialog]\n",
    "    data = {\n",
    "        'dialog': dialog,\n",
    "        'dialog_id': dialog_id,\n",
    "    }\n",
    "    dataset_test.append(data)\n",
    "\n",
    "df_train = pd.DataFrame(dataset_train)\n",
    "df_test = pd.DataFrame(dataset_test)\n",
    "\n",
    "df_train.head(3)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:11.257425Z",
     "iopub.execute_input": "2025-07-06T13:39:11.257724Z",
     "iopub.status.idle": "2025-07-06T13:39:12.331388Z",
     "shell.execute_reply.started": "2025-07-06T13:39:11.257704Z",
     "shell.execute_reply": "2025-07-06T13:39:12.330026Z"
    },
    "id": "ec53d4b5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Графики"
   ],
   "metadata": {
    "id": "3f0bbd20-e417-4bd4-8d81-cbc0194974b4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Распределение меток\n",
    "plt.figure(figsize=(10, 5))\n",
    "df_train['label'].value_counts(normalize=True).plot(kind='bar', color=['blue', 'orange', 'green'])\n",
    "plt.title('Distribution of Labels in Training Set')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=[0, 1, 2], labels=['P0 Human, P1 bot', 'P0 Bot, P1 Human', 'Both Human'], rotation=0)\n",
    "plt.show()"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:12.332664Z",
     "iopub.execute_input": "2025-07-06T13:39:12.333028Z",
     "iopub.status.idle": "2025-07-06T13:39:12.566435Z",
     "shell.execute_reply.started": "2025-07-06T13:39:12.333Z",
     "shell.execute_reply": "2025-07-06T13:39:12.564997Z"
    },
    "id": "63c1e0ef"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate counts for P0 and P1: human vs bot\n",
    "p0_counts = df_train['p0_bot'].value_counts().sort_index()\n",
    "p1_counts = df_train['p1_bot'].value_counts().sort_index()\n",
    "\n",
    "# Prepare data for barplot\n",
    "counts = [\n",
    "    [p0_counts.get(0, 0), p0_counts.get(1, 0)],  # P0: [human, bot]\n",
    "    [p1_counts.get(0, 0), p1_counts.get(1, 0)],  # P1: [human, bot]\n",
    "]\n",
    "counts = np.array(counts) / np.array(counts).sum(axis=1, keepdims=True)\n",
    "labels = ['P0', 'P1']\n",
    "categories = ['Human', 'Bot']\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.bar(x - width/2, [c[0] for c in counts], width, label='Human', color='lightblue')\n",
    "plt.bar(x + width/2, [c[1] for c in counts], width, label='Bot', color='salmon')\n",
    "plt.xticks(x, labels)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Humans and Bots for P0 and P1')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:12.568728Z",
     "iopub.execute_input": "2025-07-06T13:39:12.569135Z",
     "iopub.status.idle": "2025-07-06T13:39:12.813974Z",
     "shell.execute_reply.started": "2025-07-06T13:39:12.569111Z",
     "shell.execute_reply": "2025-07-06T13:39:12.812853Z"
    },
    "id": "f83f62aa"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Инструменты для анализа диалогов вручную"
   ],
   "metadata": {
    "id": "2c5d0b55-6ca6-4c28-a019-1a4439462c3f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_dialog_by_id(id):\n",
    "    # Using df_train\n",
    "    row = df_train.iloc[id]\n",
    "    dialog = row['dialog']\n",
    "    label = row['label']\n",
    "    return dialog, label\n",
    "\n",
    "get_dialog_by_id(4)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:12.814907Z",
     "iopub.execute_input": "2025-07-06T13:39:12.81526Z",
     "iopub.status.idle": "2025-07-06T13:39:12.823983Z",
     "shell.execute_reply.started": "2025-07-06T13:39:12.815229Z",
     "shell.execute_reply": "2025-07-06T13:39:12.82286Z"
    },
    "id": "cdae0001"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def render_dialog(dialog):\n",
    "    for item in dialog:\n",
    "        person = item['person']\n",
    "        text = item['text']\n",
    "        print(f\"{person}: {text}\")\n",
    "\n",
    "def get_dialog_by_label(label, id=0):\n",
    "    mask = df_train['label'] == label\n",
    "    dialog_id = df_train[mask]['dialog_id'].reset_index(drop=True)[id]\n",
    "    dialog = df_train[mask]['dialog'].reset_index(drop=True)[id]\n",
    "\n",
    "    print(\"Dialog ID:\", dialog_id)\n",
    "    print()\n",
    "    render_dialog(dialog)\n",
    "    print()\n",
    "\n",
    "    mask = y_train_data['dialog_id'] == dialog_id\n",
    "    data = y_train_data[mask][['dialog_id', 'participant_index', 'is_bot']]\n",
    "    data = data.sort_values(by='participant_index').reset_index(drop=True)\n",
    "    p0_bot = data['is_bot'][0]\n",
    "    p1_bot = data['is_bot'][1]\n",
    "    print(\"0 bot:\", p0_bot)\n",
    "    print(\"1 bot:\", p1_bot)\n",
    "\n",
    "get_dialog_by_label(1, 41)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:12.825138Z",
     "iopub.execute_input": "2025-07-06T13:39:12.825722Z",
     "iopub.status.idle": "2025-07-06T13:39:12.850833Z",
     "shell.execute_reply.started": "2025-07-06T13:39:12.825665Z",
     "shell.execute_reply": "2025-07-06T13:39:12.849552Z"
    },
    "id": "a1c8aa6a"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Добавляем фичи"
   ],
   "metadata": {
    "id": "913d5373-7bc8-4260-aaaa-72612b6b72cd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def add_dialog_length(df):\n",
    "    df['dialog_length'] = df['dialog'].apply(lambda x: len(x))\n",
    "    return df\n",
    "\n",
    "df_train = add_dialog_length(df_train)\n",
    "df_test = add_dialog_length(df_test)\n",
    "\n",
    "df_train.head(3)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:12.852192Z",
     "iopub.execute_input": "2025-07-06T13:39:12.853094Z",
     "iopub.status.idle": "2025-07-06T13:39:12.883425Z",
     "shell.execute_reply.started": "2025-07-06T13:39:12.853058Z",
     "shell.execute_reply": "2025-07-06T13:39:12.882265Z"
    },
    "id": "aac44722"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def add_messages_by_persons(df):\n",
    "    df['p0_messages'] = df['dialog'].apply(lambda x: [msg['text'] for msg in x if msg['person'] == '0'])\n",
    "    df['p1_messages'] = df['dialog'].apply(lambda x: [msg['text'] for msg in x if msg['person'] == '1'])\n",
    "    return df\n",
    "\n",
    "df_train = add_messages_by_persons(df_train)\n",
    "df_test = add_messages_by_persons(df_test)\n",
    "\n",
    "df_train.head(3)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:12.884711Z",
     "iopub.execute_input": "2025-07-06T13:39:12.885052Z",
     "iopub.status.idle": "2025-07-06T13:39:12.929689Z",
     "shell.execute_reply.started": "2025-07-06T13:39:12.885025Z",
     "shell.execute_reply": "2025-07-06T13:39:12.928587Z"
    },
    "id": "d7338d7e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import emoji\n",
    "\n",
    "def count_emoji(text):\n",
    "    return len([c for c in text if c in emoji.EMOJI_DATA])\n",
    "\n",
    "def add_text_features(df):\n",
    "    # Pure text\n",
    "    df['p0_text'] = df['p0_messages'].apply(lambda x: ' '.join(x))\n",
    "    df['p1_text'] = df['p1_messages'].apply(lambda x: ' '.join(x))\n",
    "    # Emoji count\n",
    "    df['p0_emoji_count'] = df['p0_text'].apply(count_emoji)\n",
    "    df['p1_emoji_count'] = df['p1_text'].apply(count_emoji)\n",
    "    # Percent of messages with emojis\n",
    "    df['p0_emoji_percent'] = df['p0_messages'].apply(lambda x: sum(1 if count_emoji(msg) > 0 else 0 for msg in x) / len(x) if len(x) > 0 else 0)\n",
    "    df['p1_emoji_percent'] = df['p1_messages'].apply(lambda x: sum(1 if count_emoji(msg) > 0 else 0 for msg in x) / len(x) if len(x) > 0 else 0)\n",
    "    # Mean length of messages\n",
    "    df['p0_mean_length'] = df['p0_messages'].apply(lambda x: np.mean([len(msg) for msg in x]) if x else 0)\n",
    "    df['p1_mean_length'] = df['p1_messages'].apply(lambda x: np.mean([len(msg) for msg in x]) if x else 0)\n",
    "    # Count of special characters: ? !\n",
    "    special_chars = ['?', '!']\n",
    "    df['p0_special_count'] = df['p0_text'].apply(lambda x: sum(x.count(char) for char in special_chars) / len(x) if len(x) > 0 else 0)\n",
    "    df['p1_special_count'] = df['p1_text'].apply(lambda x: sum(x.count(char) for char in special_chars) / len(x) if len(x) > 0 else 0)\n",
    "    # Percent of first capital letter in messages\n",
    "    df['p0_first_capital_percent'] = df['p0_messages'].apply(lambda x: sum(1 if len(msg) > 0 and msg[0].isupper() else 0 for msg in x) / len(x) if len(x) > 0 else 0)\n",
    "    df['p1_first_capital_percent'] = df['p1_messages'].apply(lambda x: sum(1 if len(msg) > 0 and msg[0].isupper() else 0 for msg in x) / len(x) if len(x) > 0 else 0)\n",
    "    # Percent of capital letters in messages\n",
    "    df['p0_capital_percent'] = df['p0_text'].apply(lambda x: sum(1 if c.isupper() else 0 for c in x) / len(x) if len(x) > 0 else 0)\n",
    "    df['p1_capital_percent'] = df['p1_text'].apply(lambda x: sum(1 if c.isupper() else 0 for c in x) / len(x) if len(x) > 0 else 0)\n",
    "    # Mean words length in messages\n",
    "    df['p0_mean_words_length'] = df['p0_text'].apply(lambda x: np.mean([len(word) for word in x.split()]) if len(x) > 0 else 0)\n",
    "    df['p1_mean_words_length'] = df['p1_text'].apply(lambda x: np.mean([len(word) for word in x.split()]) if len(x) > 0 else 0)\n",
    "    # Mean count of words in messages\n",
    "    df['p0_mean_words_count'] = df['p0_text'].apply(lambda x: np.mean([len(msg.split()) for msg in x.split('\\n')]) if len(x) > 0 else 0)\n",
    "    df['p1_mean_words_count'] = df['p1_text'].apply(lambda x: np.mean([len(msg.split()) for msg in x.split('\\n')]) if len(x) > 0 else 0)\n",
    "    # Drop pure text columns\n",
    "    df.drop(columns=['p0_text', 'p1_text'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = add_text_features(df_train)\n",
    "df_test = add_text_features(df_test)\n",
    "\n",
    "df_train.head(3)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:12.930517Z",
     "iopub.execute_input": "2025-07-06T13:39:12.930893Z",
     "iopub.status.idle": "2025-07-06T13:39:13.184737Z",
     "shell.execute_reply.started": "2025-07-06T13:39:12.930873Z",
     "shell.execute_reply": "2025-07-06T13:39:13.18354Z"
    },
    "id": "b7a347b5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def add_echo_bot_index(df):\n",
    "    # For p0 and p1 count how many their is echo of previous messages\n",
    "    def echo_count(dialog):\n",
    "        p0_echo_count = 0\n",
    "        p1_echo_count = 0\n",
    "        prev_text = None\n",
    "        for msg in dialog:\n",
    "            text = msg['text']\n",
    "            person = msg['person']\n",
    "            if prev_text and text == prev_text:\n",
    "                if person == '0':\n",
    "                    p0_echo_count += 1\n",
    "                elif person == '1':\n",
    "                    p1_echo_count += 1\n",
    "            prev_text = text\n",
    "        return p0_echo_count, p1_echo_count\n",
    "\n",
    "    df['temp'] = df['dialog'].apply(echo_count)\n",
    "    p0_echo_count = df['temp'].apply(lambda x: x[0])\n",
    "    p1_echo_count = df['temp'].apply(lambda x: x[1])\n",
    "    df.drop(columns=['temp'], inplace=True)\n",
    "\n",
    "    df['p0_echo_index'] = p0_echo_count / df['p0_messages'].apply(lambda x: len(x) - 1 if len(x) > 1 else 1)\n",
    "    df['p1_echo_index'] = p1_echo_count / df['p1_messages'].apply(lambda x: len(x) if len(x) > 0 else 1)\n",
    "    return df\n",
    "\n",
    "df_train = add_echo_bot_index(df_train)\n",
    "df_test = add_echo_bot_index(df_test)\n",
    "\n",
    "df_train.head(3)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:13.188094Z",
     "iopub.execute_input": "2025-07-06T13:39:13.188393Z",
     "iopub.status.idle": "2025-07-06T13:39:13.246124Z",
     "shell.execute_reply.started": "2025-07-06T13:39:13.188372Z",
     "shell.execute_reply": "2025-07-06T13:39:13.244857Z"
    },
    "id": "cde040b1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Learn & Predict"
   ],
   "metadata": {
    "id": "0d212f09-cacd-4cc9-ab7f-c48dfc1c162c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Подготовка данных для обучения модели"
   ],
   "metadata": {
    "id": "39d0992c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = df_train.copy()\n",
    "y_train = df_train['label'].copy()\n",
    "\n",
    "X_test = df_test.copy()\n",
    "\n",
    "def columns_filter(df):\n",
    "    BLACKLIST = [\n",
    "        'dialog', 'p0_messages', 'p1_messages',\n",
    "        'label', 'p0_bot', 'p1_bot', 'dialog_id',\n",
    "    ]\n",
    "    cols = df.columns.tolist()\n",
    "    cols = [col for col in cols if col not in BLACKLIST]\n",
    "    return df[cols]\n",
    "\n",
    "X_train = columns_filter(X_train)\n",
    "X_test = columns_filter(X_test)\n",
    "\n",
    "cols_order = X_train.columns.tolist()\n",
    "X_test = X_test[cols_order]\n",
    "\n",
    "X_train.head(3)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:13.247653Z",
     "iopub.execute_input": "2025-07-06T13:39:13.248021Z",
     "iopub.status.idle": "2025-07-06T13:39:13.279957Z",
     "shell.execute_reply.started": "2025-07-06T13:39:13.247993Z",
     "shell.execute_reply": "2025-07-06T13:39:13.279059Z"
    },
    "id": "63320543"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Обучение моделей"
   ],
   "metadata": {
    "id": "716490f2-01cb-44bf-8a9e-9539cb4ee52c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-folds"
   ],
   "metadata": {
    "id": "a0c42cad"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_labels(y):\n",
    "    label1 = y == 1  # P0 bot, P1 human => label1 = p0_bot\n",
    "    label2 = y == 0  # P0 human, P1 bot => label2 = p1_bot\n",
    "    return label1.astype(int), label2.astype(int)\n",
    "\n",
    "def get_models():\n",
    "    return {\n",
    "        'lgm': lgb.LGBMClassifier(verbose=-1, random_state=42),\n",
    "        'xgb': xgb.XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "        'cat': cat.CatBoostClassifier(verbose=0, random_state=42),\n",
    "        'rf': RandomForestClassifier(random_state=42),\n",
    "        'lr': make_pipeline(\n",
    "                StandardScaler(),\n",
    "                LogisticRegression(max_iter=1000)\n",
    "              ),\n",
    "    }\n",
    "\n",
    "\n",
    "def add_probs_to_df(df, probs1, probs2, name, indexes=None):\n",
    "    if indexes is None:\n",
    "        indexes = df.index.tolist()\n",
    "    if f'p0_prob_{name}' not in df.columns:\n",
    "        df[f'p0_prob_{name}'] = np.nan\n",
    "    if f'p1_prob_{name}' not in df.columns:\n",
    "        df[f'p1_prob_{name}'] = np.nan\n",
    "    df.loc[df.index[indexes], f'p0_prob_{name}'] = probs1[:, 1]  # P0 bot probability\n",
    "    df.loc[df.index[indexes], f'p1_prob_{name}'] = probs2[:, 1]  # P1 bot probability\n",
    "\n",
    "\n",
    "X = X_train.copy()\n",
    "y1, y2 = split_labels(y_train)\n",
    "\n",
    "X_train2 = X.copy()\n",
    "X_test2 = X_test.copy()\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "names = list(get_models().keys())\n",
    "test_probs1 = {name: np.zeros((len(X_test), 2)) for name in names}\n",
    "test_probs2 = {name: np.zeros((len(X_test), 2)) for name in names}\n",
    "\n",
    "folds_data = []\n",
    "feature_importance_data = {name : [] for name in names}\n",
    "\n",
    "for fold, (train_index, val_index) in tqdm(enumerate(kf.split(X)), desc=\"KFold Progress\", total=k):\n",
    "    X_train_fold = X.iloc[train_index]\n",
    "    y1_train_fold = y1.iloc[train_index]\n",
    "    y2_train_fold = y2.iloc[train_index]\n",
    "\n",
    "    X_val_fold = X.iloc[val_index]\n",
    "    y1_val_fold = y1.iloc[val_index]\n",
    "    y2_val_fold = y2.iloc[val_index]\n",
    "\n",
    "    # Here you can train your model on X_train_fold and validate on X_val_fold\n",
    "    models1 = get_models()\n",
    "    models2 = get_models()\n",
    "\n",
    "    val_acc1 = []\n",
    "    val_acc2 = []\n",
    "    val_logloss1 = []\n",
    "    val_logloss2 = []\n",
    "\n",
    "    for name in names:\n",
    "        tmp_model1 = models1[name]\n",
    "        tmp_model2 = models2[name]\n",
    "\n",
    "        tmp_model1.fit(X_train_fold, y1_train_fold)\n",
    "        tmp_model2.fit(X_train_fold, y2_train_fold)\n",
    "\n",
    "        probs1 = tmp_model1.predict_proba(X_val_fold)\n",
    "        probs2 = tmp_model2.predict_proba(X_val_fold)\n",
    "\n",
    "        val_acc1.append(accuracy_score(y1_val_fold, tmp_model1.predict(X_val_fold)))\n",
    "        val_acc2.append(accuracy_score(y2_val_fold, tmp_model2.predict(X_val_fold)))\n",
    "        val_logloss1.append(log_loss(y1_val_fold, probs1))\n",
    "        val_logloss2.append(log_loss(y2_val_fold, probs2))\n",
    "\n",
    "        add_probs_to_df(X_train2, probs1, probs2, name, val_index)\n",
    "\n",
    "        probs1 = tmp_model1.predict_proba(X_test2)\n",
    "        probs2 = tmp_model2.predict_proba(X_test2)\n",
    "\n",
    "        test_probs1[name] += probs1 / k\n",
    "        test_probs2[name] += probs2 / k\n",
    "\n",
    "    val_acc1 = np.mean(val_acc1)\n",
    "    val_acc2 = np.mean(val_acc2)\n",
    "    val_logloss1 = np.mean(val_logloss1)\n",
    "    val_logloss2 = np.mean(val_logloss2)\n",
    "    folds_data.append({\n",
    "        'fold': fold + 1,\n",
    "        'val_acc1': val_acc1,\n",
    "        'val_acc2': val_acc2,\n",
    "        'val_logloss1': val_logloss1,\n",
    "        'val_logloss2': val_logloss2,\n",
    "    })\n",
    "\n",
    "# Add test probabilities to X_test\n",
    "for name in names:\n",
    "    add_probs_to_df(X_test2, test_probs1[name], test_probs2[name], name)\n",
    "\n",
    "folds_data = pd.DataFrame(folds_data)\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print(f'    P0  : {folds_data[\"val_acc1\"].mean():.4f}')\n",
    "print(f'    P1  : {folds_data[\"val_acc2\"].mean():.4f}')\n",
    "print(f\"    Avg : {np.mean([folds_data['val_acc1'].mean(), folds_data['val_acc2'].mean()]):.4f}\")\n",
    "print(\"Log Loss:\")\n",
    "print(f'    P0  : {folds_data[\"val_logloss1\"].mean():.4f}')\n",
    "print(f'    P1  : {folds_data[\"val_logloss2\"].mean():.4f}')\n",
    "print(f\"    Avg : {np.mean([folds_data['val_logloss1'].mean(), folds_data['val_logloss2'].mean()]):.4f}\")\n",
    "\n",
    "folds_data"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:13.280928Z",
     "iopub.execute_input": "2025-07-06T13:39:13.2813Z",
     "iopub.status.idle": "2025-07-06T13:39:42.993809Z",
     "shell.execute_reply.started": "2025-07-06T13:39:13.281276Z",
     "shell.execute_reply": "2025-07-06T13:39:42.99301Z"
    },
    "id": "28c26961"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def get_stats(y_true, y_pred, show_cm=True, names=None):\n",
    "    names = ['p1 bot', 'p0 bot', 'both human'] if names is None else names\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, target_names=names)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "    if show_cm:\n",
    "        # Show confusion matrix as a heatmap\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=names,\n",
    "                    yticklabels=names)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return acc"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:42.994539Z",
     "iopub.execute_input": "2025-07-06T13:39:42.994801Z",
     "iopub.status.idle": "2025-07-06T13:39:43.00756Z",
     "shell.execute_reply.started": "2025-07-06T13:39:42.994777Z",
     "shell.execute_reply": "2025-07-06T13:39:43.004616Z"
    },
    "id": "b517a48c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# TF-IDF\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def get_texts_p0(df):\n",
    "    return df['p0_messages'].apply(lambda x: '\\n'.join(x)).to_list()\n",
    "\n",
    "def get_texts_p1(df):\n",
    "    return df['p1_messages'].apply(lambda x: '\\n'.join(x)).to_list()\n",
    "\n",
    "def get_bot_texts(df):\n",
    "    df = df.copy()\n",
    "    p0_bot = df['p0_bot'] == 1\n",
    "    p1_bot = df['p1_bot'] == 1\n",
    "    texts1 = get_texts_p0(df[p0_bot])\n",
    "    texts2 = get_texts_p1(df[p1_bot])\n",
    "    return texts1 + texts2\n",
    "\n",
    "def get_human_texts(df):\n",
    "    df = df.copy()\n",
    "    p0_bot = df['p0_bot'] == 0\n",
    "    p1_bot = df['p1_bot'] == 0\n",
    "    texts1 = get_texts_p0(df[p0_bot])\n",
    "    texts2 = get_texts_p1(df[p1_bot])\n",
    "    return texts1 + texts2\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Удалить ссылки\n",
    "    text = re.sub(r'\\s+', ' ', text)                   # Удалить лишние пробелы\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)                # Удалить пунктуацию\n",
    "    return text.strip()\n",
    "\n",
    "def get_tfidf_probs(df, vectorizer, model_tfidf):\n",
    "    texts1 = get_texts_p0(df)\n",
    "    texts2 = get_texts_p1(df)\n",
    "\n",
    "    texts1 = [preprocess(text) for text in texts1]\n",
    "    texts2 = [preprocess(text) for text in texts2]\n",
    "\n",
    "    vec1 = vectorizer.transform(texts1)\n",
    "    vec2 = vectorizer.transform(texts2)\n",
    "\n",
    "    probs1 = model_tfidf.predict_proba(vec1)\n",
    "    probs2 = model_tfidf.predict_proba(vec2)\n",
    "\n",
    "    return probs1, probs2\n",
    "\n",
    "\n",
    "y1, y2 = split_labels(y_train)\n",
    "\n",
    "folds_data_tfidf = []\n",
    "test_probs1 = np.zeros((len(X_test2), 2))\n",
    "test_probs2 = np.zeros((len(X_test2), 2))\n",
    "\n",
    "for fold, (train_indexes, val_indexes) in tqdm(enumerate(kf.split(X_train)), desc=\"KFold Progress\", total=k):\n",
    "    # Split data into training and validation sets\n",
    "    X_train_fold = df_train.copy().iloc[train_indexes]\n",
    "    y1_train_fold = y1.iloc[train_indexes]\n",
    "    y2_train_fold = y2.iloc[train_indexes]\n",
    "\n",
    "    X_val_fold = df_train.copy().iloc[val_indexes]\n",
    "    y1_val_fold = y1.iloc[val_indexes]\n",
    "    y2_val_fold = y2.iloc[val_indexes]\n",
    "\n",
    "    # Get texts for training and validation\n",
    "    human_texts_train = get_human_texts(X_train_fold)\n",
    "    bot_texts_train = get_bot_texts(X_train_fold)\n",
    "    human_texts_val = get_human_texts(X_val_fold)\n",
    "    bot_texts_val = get_bot_texts(X_val_fold)\n",
    "\n",
    "    # Preprocess texts\n",
    "    human_texts_train = [preprocess(msg) for msg in human_texts_train]\n",
    "    bot_texts_train = [preprocess(msg) for msg in bot_texts_train]\n",
    "    human_texts_val = [preprocess(msg) for msg in human_texts_val]\n",
    "    bot_texts_val = [preprocess(msg) for msg in bot_texts_val]\n",
    "\n",
    "    # Prepare texts for training and validation\n",
    "    X_train_texts = bot_texts_train + human_texts_train\n",
    "    y_train_texts = [1] * len(bot_texts_train) + [0] * len(human_texts_train) # 1 = bot, 0 = human\n",
    "    X_val_texts = bot_texts_val + human_texts_val\n",
    "    y_val_texts = [1] * len(bot_texts_val) + [0] * len(human_texts_val) # 1 = bot, 0 = human\n",
    "\n",
    "    # Vectorization\n",
    "    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(2, 3), analyzer='char')\n",
    "    X_train_vec = vectorizer.fit_transform(X_train_texts)\n",
    "    X_val_vec = vectorizer.transform(X_val_texts)\n",
    "\n",
    "    # Train model\n",
    "    model_tfidf = LogisticRegression(max_iter=1000)\n",
    "    model_tfidf.fit(X_train_vec, y_train_texts)\n",
    "\n",
    "    probs1, probs2 = get_tfidf_probs(X_val_fold, vectorizer, model_tfidf)\n",
    "    add_probs_to_df(X_train2, probs1, probs2, 'tfidf', val_indexes)\n",
    "\n",
    "    preds1 = (probs1[:, 1] > 0.5).astype(int)  # P0 bot\n",
    "    preds2 = (probs2[:, 1] > 0.5).astype(int)  # P1 bot\n",
    "\n",
    "    folds_data_tfidf.append({\n",
    "        'fold': fold + 1,\n",
    "        'val_acc1': accuracy_score(y1_val_fold, preds1),\n",
    "        'val_acc2': accuracy_score(y2_val_fold, preds2),\n",
    "        'val_logloss1': log_loss(y1_val_fold, probs1),\n",
    "        'val_logloss2': log_loss(y2_val_fold, probs2),\n",
    "    })\n",
    "\n",
    "    probs1, probs2 = get_tfidf_probs(df_test, vectorizer, model_tfidf)\n",
    "    test_probs1 += probs1 / k\n",
    "    test_probs2 += probs2 / k\n",
    "\n",
    "# Add test probabilities to X_test2\n",
    "add_probs_to_df(X_test2, test_probs1, test_probs2, 'tfidf')\n",
    "\n",
    "folds_data_tfidf = pd.DataFrame(folds_data_tfidf)\n",
    "print(\"TF-IDF Accuracy:\")\n",
    "print(f'    P0  : {folds_data_tfidf[\"val_acc1\"].mean():.4f}')\n",
    "print(f'    P1  : {folds_data_tfidf[\"val_acc2\"].mean():.4f}')\n",
    "print(f\"    Avg : {np.mean([folds_data_tfidf['val_acc1'].mean(), folds_data_tfidf['val_acc2'].mean()]):.4f}\")\n",
    "print(\"TF-IDF Log Loss:\")\n",
    "print(f'    P0  : {folds_data_tfidf[\"val_logloss1\"].mean():.4f}')\n",
    "print(f'    P1  : {folds_data_tfidf[\"val_logloss2\"].mean():.4f}')\n",
    "print(f\"    Avg : {np.mean([folds_data_tfidf['val_logloss1'].mean(), folds_data_tfidf['val_logloss2'].mean()]):.4f}\")\n",
    "\n",
    "\n",
    "folds_data_tfidf"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:43.010437Z",
     "iopub.execute_input": "2025-07-06T13:39:43.011256Z",
     "iopub.status.idle": "2025-07-06T13:39:46.98606Z",
     "shell.execute_reply.started": "2025-07-06T13:39:43.011223Z",
     "shell.execute_reply": "2025-07-06T13:39:46.985187Z"
    },
    "id": "3c9c12fc"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "possbible_models = {\n",
    "    'lr' : lambda : make_pipeline(\n",
    "                StandardScaler(),\n",
    "                LogisticRegression(max_iter=1000, random_state=42)\n",
    "              ),\n",
    "    'lgm' : lambda : lgb.LGBMClassifier(verbose=-1, random_state=42),\n",
    "    'rf': lambda : RandomForestClassifier(random_state=42),\n",
    "}\n",
    "choose_model = 'lr'\n",
    "get_meta_model = possbible_models[choose_model]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = X_train2.copy()\n",
    "y = y_train.copy()\n",
    "\n",
    "# Drop evevrything except probabilities\n",
    "cols_probs = [col for col in X.columns if col.startswith('p0_prob_') or col.startswith('p1_prob_')]\n",
    "X = X[cols_probs]\n",
    "X_test2 = X_test2[cols_probs]\n",
    "\n",
    "# split\n",
    "X_train_meta, X_val_meta, y_train_meta, y_val_meta = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "label1_train, label2_train = split_labels(y_train_meta)\n",
    "label1_val, label2_val = split_labels(y_val_meta)\n",
    "\n",
    "def fit_and_test(model, X_train, y_train, X_val, y_val, exp_name=None):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    probs = model.predict_proba(X_val)\n",
    "    if exp_name: print(\"Exp: \", exp_name)\n",
    "    logloss = log_loss(y_val, probs)\n",
    "    print(f\"Log Loss: {logloss:.4f}\")\n",
    "    acc = get_stats(y_val, y_pred, show_cm=False, names=['Human', 'Bot'])\n",
    "    print(acc)\n",
    "    return acc, logloss\n",
    "\n",
    "meta_model1 = get_meta_model()\n",
    "acc1, logloss1 = fit_and_test(meta_model1, X_train_meta, label1_train, X_val_meta, label1_val, exp_name='P0 Bot Meta Model')\n",
    "\n",
    "meta_model2 = get_meta_model()\n",
    "acc2, logloss2 = fit_and_test(meta_model2, X_train_meta, label2_train, X_val_meta, label2_val, exp_name='P1 Bot Meta Model')\n",
    "\n",
    "print(f\"Mean accuracy: {(acc1 + acc2) / 2:.4f}\")\n",
    "print(f\"Mean log loss: {(logloss1 + logloss2) / 2:.4f}\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:46.987299Z",
     "iopub.execute_input": "2025-07-06T13:39:46.987574Z",
     "iopub.status.idle": "2025-07-06T13:39:47.245245Z",
     "shell.execute_reply.started": "2025-07-06T13:39:46.987555Z",
     "shell.execute_reply": "2025-07-06T13:39:47.244458Z"
    },
    "id": "06c9e54e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create submission file"
   ],
   "metadata": {
    "id": "953c11d1-7899-424f-9328-431dc2bafc4f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Choose model for submission\n",
    "probs1 = meta_model1.predict_proba(X_test2)[:, 1] # P0 bot probability\n",
    "probs2 = meta_model2.predict_proba(X_test2)[:, 1] # P1 bot probability\n",
    "\n",
    "df = df_test[['dialog_id']].copy()\n",
    "df['is_bot_0'] = probs1\n",
    "df['is_bot_1'] = probs2\n",
    "\n",
    "df.head(3)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:47.246307Z",
     "iopub.execute_input": "2025-07-06T13:39:47.246595Z",
     "iopub.status.idle": "2025-07-06T13:39:47.272964Z",
     "shell.execute_reply.started": "2025-07-06T13:39:47.246571Z",
     "shell.execute_reply": "2025-07-06T13:39:47.271823Z"
    },
    "id": "c403dab2"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def get_is_bot(ID):\n",
    "    global df\n",
    "    temp = ID.split('_')\n",
    "    dialog_id = temp[0]\n",
    "    person = temp[1]\n",
    "    mask = df['dialog_id'] == dialog_id\n",
    "    data = df[mask].reset_index(drop=True)\n",
    "    if person == '0':\n",
    "        return data['is_bot_0'][0]\n",
    "    elif person == '1':\n",
    "        return data['is_bot_1'][0]\n",
    "\n",
    "\n",
    "submission_path = pathlib.Path(\"outputs\") / \"submission.csv\"\n",
    "submission['is_bot'] = submission['ID'].apply(get_is_bot).astype('float32')\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "submission = pd.read_csv(submission_path)\n",
    "submission"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:40:29.264609Z",
     "iopub.execute_input": "2025-07-06T13:40:29.264908Z",
     "iopub.status.idle": "2025-07-06T13:40:29.596186Z",
     "shell.execute_reply.started": "2025-07-06T13:40:29.264889Z",
     "shell.execute_reply": "2025-07-06T13:40:29.59533Z"
    },
    "id": "2d5c3b9c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Post submission"
   ],
   "metadata": {
    "id": "6f7f01a5-0c3b-4114-9f8f-1eb25f950339"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Importance"
   ],
   "metadata": {
    "id": "36e21e1e"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Meta models feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_feature_importance(model, X_train, title):\n",
    "    feature_importances = model.feature_importances_ if hasattr(model, 'feature_importances_') else model.named_steps['logisticregression'].coef_[0]\n",
    "    feature_names = X_train.columns if hasattr(X_train, 'columns') else [f'Feature {i}' for i in range(len(feature_importances))]\n",
    "\n",
    "    # Create a DataFrame for better visualization\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_importance(meta_model1, X_train_meta, 'P0 Bot Meta Model Feature Importance')\n",
    "plot_feature_importance(meta_model2, X_train_meta, 'P1 Bot Meta Model Feature Importance')\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:47.624976Z",
     "iopub.execute_input": "2025-07-06T13:39:47.625314Z",
     "iopub.status.idle": "2025-07-06T13:39:48.125919Z",
     "shell.execute_reply.started": "2025-07-06T13:39:47.625287Z",
     "shell.execute_reply": "2025-07-06T13:39:48.124838Z"
    },
    "id": "f90dbecc"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predictions examples"
   ],
   "metadata": {
    "id": "c8af9c12-095d-4673-8b1b-eb3408867a16"
   }
  },
  {
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T13:39:48.127158Z",
     "iopub.execute_input": "2025-07-06T13:39:48.127437Z",
     "iopub.status.idle": "2025-07-06T13:39:48.147438Z",
     "shell.execute_reply.started": "2025-07-06T13:39:48.127413Z",
     "shell.execute_reply": "2025-07-06T13:39:48.146039Z"
    },
    "id": "ba5b1d45"
   },
   "cell_type": "code",
   "source": [
    "# Покажем несколько случайных диалогов из теста и вероятности для p1 (test_probs2)\n",
    "num_samples = 5\n",
    "\n",
    "sample_indices = np.random.choice(len(df_test), num_samples, replace=False)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    dialog_id = df_test.iloc[idx]['dialog_id']\n",
    "    dialog = df_test.iloc[idx]['dialog']\n",
    "    print(f\"Dialog ID: {dialog_id}\")\n",
    "    print(\"Диалог:\")\n",
    "    render_dialog(dialog)\n",
    "    mask = dialog_id == df['dialog_id']\n",
    "    p0, p1 = df[mask][['is_bot_0', 'is_bot_1']].values[0]\n",
    "    print()\n",
    "    print(f\"P0 Bot prob: {p0:.4f}\\nP1 Bot prob: {p1:.4f}\")\n",
    "    print('-' * 60)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}
